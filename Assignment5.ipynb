{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLv6vqpaXj787IvC3u49+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanishasharma11/Assignment-05-R-Programming/blob/main/Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Create a file that contains 1000 lines of random strings."
      ],
      "metadata": {
        "id": "Q1oOkw6UF1nq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03sRVUiPFtDV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "file_path = \"random_strings.txt\"\n",
        "num_lines = 1000\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "    for _ in range(num_lines):\n",
        "        random_string = generate_random_string(10)  # Change the length as needed\n",
        "        file.write(random_string + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Create a random dataset of 100 rows and 30 columns. All the values are defined between [1,200]"
      ],
      "metadata": {
        "id": "aQVBBkeDF5Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "num_rows = 100\n",
        "num_columns = 30\n",
        "\n",
        "data = []\n",
        "for _ in range(num_rows):\n",
        "    row = [random.randint(1, 200) for _ in range(num_columns)]\n",
        "    data.append(row)\n",
        "\n",
        "file_path = \"random_dataset.csv\"\n",
        "\n",
        "with open(file_path, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "p23l7CgaF_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform\n",
        "the following operations:\n",
        "(i) Replace all the values with NA in the dataset defined between [10, 60]. Print the count of number\n",
        "rows having missing values.\n",
        "(ii) Replace all the NA values with the average of the column value.\n",
        "(iii) Find the Pearson correlation among all the columns and plot heat map. Also select those columns\n",
        "having correlation <=0.7.\n",
        "(iv) Normalize all the values in the dataset between 0 and 10.\n",
        "(v) Replace all the values in the dataset with 1 if value <=0.5 else with 0."
      ],
      "metadata": {
        "id": "32Nm1MjCGBaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "data = pd.read_csv(\"random_dataset.csv\")\n",
        "\n",
        "# (i) Replace values between 10 and 60 with NA\n",
        "data.replace(np.arange(10, 61), np.nan, inplace=True)\n",
        "\n",
        "# Count the number of rows with missing values\n",
        "num_rows_with_missing = data.isnull().any(axis=1).sum()\n",
        "print(\"Number of rows with missing values:\", num_rows_with_missing)\n",
        "\n",
        "# (ii) Replace NA values with column averages\n",
        "column_means = data.mean()\n",
        "data.fillna(column_means, inplace=True)\n",
        "\n",
        "# (iii) Calculate Pearson correlation and plot heatmap\n",
        "correlation_matrix = data.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Pearson Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Select columns with correlation <= 0.7\n",
        "selected_columns = correlation_matrix.columns[correlation_matrix.abs().le(0.7).all()]\n",
        "print(\"Columns with correlation <= 0.7:\", selected_columns)\n",
        "\n",
        "# (iv) Normalize values between 0 and 10\n",
        "data_normalized = (data - data.min()) / (data.max() - data.min()) * 10\n",
        "\n",
        "# (v) Replace values <= 0.5 with 1, else with 0\n",
        "data_replaced = data_normalized.applymap(lambda x: 1 if x <= 0.5 else 0)\n"
      ],
      "metadata": {
        "id": "ovZ3wmSZGIRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Create a random dataset of 500 rows and 10 columns.\n",
        "Columns 1 to 4 are defined between [-10, 10];\n",
        "Columns 5 to 8 are defined between [10, 20];\n",
        "Columns 9 to 10 are defined between [-100, 100]."
      ],
      "metadata": {
        "id": "0h-TouQKGQOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "num_rows = 500\n",
        "num_columns = 10\n",
        "\n",
        "data = []\n",
        "for _ in range(num_rows):\n",
        "    row = [\n",
        "        random.uniform(-10, 10) if 1 <= i <= 4 else\n",
        "        random.uniform(10, 20) if 5 <= i <= 8 else\n",
        "        random.uniform(-100, 100)\n",
        "        for i in range(1, num_columns + 1)\n",
        "    ]\n",
        "    data.append(row)\n",
        "\n",
        "file_path = \"random_dataset.csv\"\n",
        "\n",
        "with open(file_path, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "5NSkuPbQGeDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply following clustering algorithms; determine the optimal number of clusters and plot distance metric\n",
        "graph using each algorithm.\n",
        "(i) K-Mean clustering\n",
        "(ii) Hierarchical clustering"
      ],
      "metadata": {
        "id": "v-m2a9rHGgqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "data = pd.read_csv(\"random_dataset.csv\")\n",
        "\n",
        "# Convert the dataset to a numpy array\n",
        "X = data.to_numpy()\n",
        "\n",
        "# Determine the optimal number of clusters for K-Means using silhouette score\n",
        "silhouette_scores = []\n",
        "max_clusters = 10\n",
        "for n_clusters in range(2, max_clusters+1):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plot the silhouette scores for different number of clusters\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(2, max_clusters+1), silhouette_scores, marker='o')\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.title(\"Silhouette Score vs Number of Clusters (K-Means)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Determine the optimal number of clusters for Hierarchical clustering using dendrogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Dendrogram (Hierarchical Clustering)\")\n",
        "dendrogram = dendrogram(\n",
        "    np.array(X),\n",
        "    truncate_mode='level',\n",
        "    p=10,\n",
        "    show_leaf_counts=True\n",
        ")\n",
        "plt.xlabel(\"Data Point Index\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()\n",
        "\n",
        "# Apply K-Means clustering with the optimal number of clusters\n",
        "k = 3  # Choose the optimal number of clusters based on the silhouette score plot\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(X)\n",
        "\n",
        "# Apply Hierarchical clustering with the optimal number of clusters\n",
        "hc = AgglomerativeClustering(n_clusters=k)\n",
        "hc_labels = hc.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "LzeSm4rjGjhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Create a random dataset of 600 rows and 15 columns. All the values are defined between [-100,100]. "
      ],
      "metadata": {
        "id": "YD9hH6o0Gvdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "num_rows = 600\n",
        "num_columns = 15\n",
        "\n",
        "data = []\n",
        "for _ in range(num_rows):\n",
        "    row = [random.uniform(-100, 100) for _ in range(num_columns)]\n",
        "    data.append(row)\n",
        "\n",
        "file_path = \"random_dataset.csv\"\n",
        "\n",
        "with open(file_path, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "3xS1GaoSGzDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform the following operations:\n",
        "(i) Plot scatter graph between Column 5 and Column 6.\n",
        "(ii) Plot histogram of each column in single graph.\n",
        "(iii) Plot the Box plot of each column in single graph."
      ],
      "metadata": {
        "id": "q9kFyJYZHD_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "data = pd.read_csv(\"random_dataset.csv\")\n",
        "\n",
        "# (i) Plot scatter graph between Column 5 and Column 6\n",
        "column_5 = data.iloc[:, 4]  # Selecting the 5th column (index 4)\n",
        "column_6 = data.iloc[:, 5]  # Selecting the 6th column (index 5)\n",
        "plt.scatter(column_5, column_6)\n",
        "plt.xlabel(\"Column 5\")\n",
        "plt.ylabel(\"Column 6\")\n",
        "plt.title(\"Scatter Plot: Column 5 vs Column 6\")\n",
        "plt.show()\n",
        "\n",
        "# (ii) Plot histogram of each column in a single graph\n",
        "data.hist(figsize=(12, 8), bins=20)\n",
        "plt.tight_layout()\n",
        "plt.suptitle(\"Histogram of Each Column\")\n",
        "plt.show()\n",
        "\n",
        "# (iii) Plot the Box plot of each column in a single graph\n",
        "data.boxplot(figsize=(12, 8))\n",
        "plt.title(\"Box Plot of Each Column\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ufHCEaYEHIrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Create a random dataset of 500 rows and 5 columns:\n",
        "All the values are defined between [5,10]."
      ],
      "metadata": {
        "id": "OWoWFxFhHWZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import csv\n",
        "\n",
        "num_rows = 500\n",
        "num_columns = 5\n",
        "\n",
        "data = []\n",
        "for _ in range(num_rows):\n",
        "    row = [random.uniform(5, 10) for _ in range(num_columns)]\n",
        "    data.append(row)\n",
        "\n",
        "file_path = \"random_dataset.csv\"\n",
        "\n",
        "with open(file_path, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "CsZaxfJxHZIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform the following operations:\n",
        "(i) Perform t-Test on each column.\n",
        "(ii) Perform Wilcoxon Signed Rank Test on each column.\n",
        "(iii) Perform Two Sample t-Test and Wilcoxon Rank Sum Test on Column 3 and Column 4"
      ],
      "metadata": {
        "id": "-7o1ItQiHgNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import ttest_1samp, wilcoxon, ttest_ind, ranksums\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "data = pd.read_csv(\"random_dataset.csv\")\n",
        "\n",
        "# (i) Perform t-Test on each column\n",
        "t_test_results = {}\n",
        "for column in data.columns:\n",
        "    t_statistic, p_value = ttest_1samp(data[column], popmean=7.5)  # Assuming popmean as 7.5\n",
        "    t_test_results[column] = {\"t_statistic\": t_statistic, \"p_value\": p_value}\n",
        "\n",
        "# (ii) Perform Wilcoxon Signed Rank Test on each column\n",
        "wilcoxon_results = {}\n",
        "for column in data.columns:\n",
        "    statistic, p_value = wilcoxon(data[column] - 7.5)  # Assuming popmean as 7.5\n",
        "    wilcoxon_results[column] = {\"statistic\": statistic, \"p_value\": p_value}\n",
        "\n",
        "# (iii) Perform Two Sample t-Test and Wilcoxon Rank Sum Test on Column 3 and Column 4\n",
        "column_3 = data[\"Column 3\"]\n",
        "column_4 = data[\"Column 4\"]\n",
        "t_test_2samp_result = ttest_ind(column_3, column_4)\n",
        "wilcoxon_ranksums_result = ranksums(column_3, column_4)\n",
        "\n",
        "# Print the results\n",
        "print(\"(i) t-Test Results:\")\n",
        "for column, result in t_test_results.items():\n",
        "    print(\"Column:\", column)\n",
        "    print(\"  t-statistic:\", result[\"t_statistic\"])\n",
        "    print(\"  p-value:\", result[\"p_value\"])\n",
        "\n",
        "print(\"\\n(ii) Wilcoxon Signed Rank Test Results:\")\n",
        "for column, result in wilcoxon_results.items():\n",
        "    print(\"Column:\", column)\n",
        "    print(\"  statistic:\", result[\"statistic\"])\n",
        "    print(\"  p-value:\", result[\"p_value\"])\n",
        "\n",
        "print(\"\\n(iii) Two Sample t-Test and Wilcoxon Rank Sum Test on Column 3 and Column 4\")\n",
        "print(\"t-Test 2-Sample Result:\")\n",
        "print(\"  t-statistic:\", t_test_2samp_result.statistic)\n",
        "print(\"  p-value:\", t_test_2samp_result.pvalue)\n",
        "\n",
        "print(\"\\nWilcoxon Rank Sum Test Result:\")\n",
        "print(\"  statistic:\", wilcoxon_ranksums_result.statistic)\n",
        "print(\"  p-value:\", wilcoxon_ranksums_result.pvalue)\n"
      ],
      "metadata": {
        "id": "FYPDnJm3HjX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}